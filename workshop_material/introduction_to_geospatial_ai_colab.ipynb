{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emBCk06ovP1q"
      },
      "source": [
        "# Introduction to Geospatial AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "Welcome to this workshop about geospatial AI! In this workshop you will try to detect buildings from aerial images. This is done in three steps;\n",
        "\n",
        "1. Creating training data. We have two different sources of data; A WMS containing aerial images and an OpenStreetMap database to get the locations of buildings.\n",
        "2. Training machine learning models using the created training data.\n",
        "3. Evaluating the trained models and predicting where buildings are located in images the models haven't seen before. \n",
        "\n",
        "We will be using jupyter notebooks with Google Colab, but you don't need to have any experience with these in order to complete this workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 0.0 - Select GPU env\n",
        "\n",
        "But first, we need to change the runtime to a GPU. In the top right corner click the \"triangle\" and choose `Change runtime type` and select `T4 GPU`.\n",
        "\n",
        "Next, we need to clone the git repo we are working with and install some dependencies. To do this simply run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fEENVoCvP1q",
        "outputId": "32b51360-456b-468f-de33-dc6c26a0eb55"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kartAI/kartAI.git\n",
        "!git -C /content/kartAI/ checkout origin/workshop env.py\n",
        "\n",
        "!pip install focal_loss\n",
        "!pip install azure-storage-blob\n",
        "!pip install rasterio\n",
        "!pip install rasterstats\n",
        "!pip install colour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 0.1 - Insert secrets\n",
        "\n",
        "The next step is to insert secrets. Here is how to do it;\n",
        "\n",
        "1. Go to the github gist (where you found the link to this notebook)\n",
        "2. Insert the secrets in the next cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDdbVLf5vP1r"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.insert(0,'/content/kartAI')\n",
        "\n",
        "os.environ['NK_WMS_API_KEY'] = \"Insert WMS secret here\"\n",
        "os.environ['OSM_DB_PWD'] = \"Insert DB secret here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1.1 - Select your training dataset\n",
        "\n",
        "Your first task is to select which area you want to create training data for. \n",
        "\n",
        "1. Select a name for your area by changing the variable \"training_dataset_name\"\n",
        "2. Choose an area by uncommenting the code for one of our three predefined areas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the name of your training set\n",
        "training_dataset_name = \"best_training_dataset\"\n",
        "\n",
        "\"\"\" Uncomment (remove the #) for the area you want to use \"\"\"\n",
        "\n",
        "\"\"\" This area covers Sand, outside of Jessheim \"\"\"\n",
        "# area = { \"x_min\": 618296.0, \"x_max\": 620895.0, \"y_min\": 6668145.0, \"y_max\": 6670133.0 }\n",
        "\n",
        "\"\"\" This area covers Skøyen, Oslo \"\"\"\n",
        "# area = { \"x_min\": 593150.9, \"x_max\": 596528.0, \"y_min\": 6643812.3, \"y_max\": 6644452.2 }\n",
        "\n",
        "\"\"\" This area covers Midtbyen, Trondheim \"\"\";\n",
        "# area = { \"x_min\": 568372.6, \"x_max\": 570820.4, \"y_min\": 7033216.7, \"y_max\": 7034223.7 }\n",
        "\n",
        "try:\n",
        "  print(f\"Woho!\\nSelected area {area} with name {training_dataset_name}\")\n",
        "except:\n",
        "  print(\"ERROR! \\nYou have not selected one of the areas to create data for. Uncomment one of the tree options in the cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1.2 - Create training data\n",
        "Your next task is to create training data for your selected area. \n",
        "\n",
        "The training data is downloaded as rasters (images) and added to a new directory called \"training_data\", that can be seen in the directory menu on the left. The data is split into training, validation and test. \n",
        "\n",
        "While downloading the rasters, it will say how many rasters that will be downloaded in total. \n",
        "The process is time consuming, and will take around 10 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vAvL9gJ2vP1r",
        "outputId": "8be86582-9805-4289-d091-1c33c684e8b7"
      },
      "outputs": [],
      "source": [
        "from kartAI.kartai.tools.create_training_data import create_training_data\n",
        "import os\n",
        "\n",
        "# If there already are downloaded images, we wipe them to avoid messing up the file paths and visualizations.\n",
        "try: \n",
        "  dir = \"/content/training_data/OrtofotoWMS/25832_563000.0_6623000.0_100.0_100.0/512/\"\n",
        "  for f in os.listdir(dir):\n",
        "      os.remove(os.path.join(dir, f))\n",
        "except FileNotFoundError:\n",
        "  pass\n",
        "\n",
        "\n",
        "create_training_data(\n",
        "    training_dataset_name=training_dataset_name, \n",
        "    config_file_path=\"kartAI/config/dataset/osm_bygg.json\",\n",
        "    eager_load=True,\n",
        "    confidence_threshold=None, \n",
        "    eval_model_checkpoint=None,\n",
        "    region=None, \n",
        "    x_min=area[\"x_min\"], \n",
        "    x_max=area[\"x_max\"], \n",
        "    y_min=area[\"y_min\"], \n",
        "    y_max=area[\"y_max\"],\n",
        "    num_processes=None                 \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1.3 - Visualize training data\n",
        "After downloading the data you can visualize it in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "from pyproj import CRS, Transformer\n",
        "\n",
        "path_to_dir = \"/content/training_data/OrtofotoWMS/25832_563000.0_6623000.0_100.0_100.0/512/\"\n",
        "files = os.listdir(path_to_dir)\n",
        "files.sort()\n",
        "\n",
        "crs_25832 = CRS.from_epsg(25832)\n",
        "crs_4326 = CRS.from_epsg(4326)\n",
        "transformer = Transformer.from_crs(crs_25832, crs_4326)\n",
        "\n",
        "fig = folium.Figure(width=800, height=400)\n",
        "m = folium.Map(\n",
        "    location=transformer.transform(area[\"x_min\"], area[\"y_max\"]), \n",
        "    zoom_start=14\n",
        ")\n",
        "\n",
        "for i in range(5): # Load 5 rasters. Change this to load fewer/more rasters. Be aware that loading many rasters is slow.\n",
        "    with rasterio.open(f\"{path_to_dir}{files[i]}\") as src:\n",
        "        img = src.read()\n",
        "        transformed_bottom_left = transformer.transform(src.bounds.left, src.bounds.bottom)\n",
        "        transformed_top_right = transformer.transform(src.bounds.right, src.bounds.top)\n",
        "    m.add_child(folium.raster_layers.ImageOverlay(img.transpose(1, 2, 0), bounds = [transformed_bottom_left, transformed_top_right]))\n",
        "\n",
        "fig.add_child(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2.1 - Choose model type and hyperparameters\n",
        "After creating and visualizing the training data we are ready to train our model! Before we start training the model we need to decide what kind of model you want to build. Give your model a name and choose hyperparameters you want to work with.\n",
        "\n",
        "The `model` argument below decides what kind of model architecture you want to use. The supported ones are \n",
        " - `unet`. The “U-Net” architecture consists of 2 parts: the first part is a “classic” Convolutional Neural Network which scans the image, extract patterns from it, and combine them into high resolutions features. Then, the network is asked to upscale its hidden layers into recreating a full binary image, where each pixel is either 0 or 1.\n",
        " - `resnet`. Residual Network (ResNet) architecture is a type of artificial neural network that allows the model to skip layers without affecting performance and therefore circumventing the vanishing gradient problem.\n",
        " - `CSP`. A Cross Stage Partial (CSP) block is designed to attribute the problem of duplicate gradient information within network optimization. The input is split into two paths, where one path is goes through a dense block, while the other skips the block and joins at the end. This means complexity can be reduced while maintaining the accuracy.\n",
        "\n",
        "If you want to know more about the models and their architecture feel free to ask us or google them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose model name and architecture\n",
        "model_name = \"super_ultra_wow_model\"\n",
        "model_architecture = \"unet\" #CSP, resnet\n",
        "\n",
        "train_args = {\n",
        "      \"features\": 32,\n",
        "      \"depth\": 4,\n",
        "      \"optimizer\": \"RMSprop\",\n",
        "      \"batch_size\": 8,\n",
        "      \"model\": model_architecture,\n",
        "      \"loss\": \"binary_crossentropy\",\n",
        "      \"activation\": \"relu\",\n",
        "      \"epochs\": 20\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2.2 - Train your own machine learning model\n",
        "The models you're about to train performs what is known as a per-pixel classification. In other words, the model tries to assign a class (either a building or not a building) for each pixel in the raster based on the input features. After the model is trained we can create vector data from the predicted pixels and therefore end up with bounding boxes we can look at!\n",
        "\n",
        "In the next cell you can tune some hyperparameters, but make sure the training doesn't take too long. The default configuration should take about ~15 minutes to execute and should get you a _decent_ model.\n",
        "\n",
        "While training, the terminal will print some statistics. These can be a little bit confusing, and it's not a must to understand all of them. The stats showing are;\n",
        "\n",
        " - Loss: A measurement of how wrong the model is. The lower the loss is, the better. If the loss is 0, the model is \"perfect\". A model tries to minimize this value.\n",
        " - Binary Accuracy: A measurement of how many of the predicted pixels are inside a building. It's a number between 0 and 1, where higher is better. 1 means all the pixels the model says are within a building is actually within a building. But keep in mind even if the number is 1, the model might not have made predictions for all pixels in all buildings...\n",
        " - IoU: Intersection over Union. A measurement of how much of the estimated area overlaps with a building. It's a number between 0 and 1, where higher is better. 1 means the model is fitting the bounding box of all buildings \"perfectly\".\n",
        " - IoU_fz: Fuzzy set variant of IoU. Shares similar characteristics as described earlier.\n",
        " - IoU_point_[5-9]: Cutoff values for IoU. It's a measurement of what the IoU would be if the cutoff values was [5-9].\n",
        " - val_x: The validation equivalent of whatever x is. X could be loss, IoU, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s07L5WvTJhLz",
        "outputId": "1b2ba046-e93b-4ec3-ca36-36bd2bc5eba6"
      },
      "outputs": [],
      "source": [
        "from kartAI.kartai.tools.train import train\n",
        "\n",
        "train(\n",
        "      checkpoint_name=model_name,\n",
        "      dataset_name=[training_dataset_name],\n",
        "      input_generator_config_path=\"kartAI/config/ml_input_generator/ortofoto.json\",\n",
        "      save_model=False, #To cloud, local saving is default\n",
        "      train_args=train_args,\n",
        "      checkpoint_to_finetune=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.1 - Running inference on test set\n",
        "For task 3 we will use our trained machine learning model and try to find buildings in a new set of images we haven't seen so far. The next cell runs predictions on the test portion of the downloaded training data. The same statistics as the ones described during training shows up, in addition to;\n",
        "\n",
        " - Confidence: Tells us how confident the model is. It is a number between 0 and 1, where higher is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_aMcP6Njm3d",
        "outputId": "0874bd77-9ad4-4be9-b4ab-a5925bfd5593"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from kartAI.env import get_env_variable\n",
        "from kartAI.kartai.tools.predict import predict_and_evaluate\n",
        "\n",
        "created_datasets_dir = os.path.join(get_env_variable(\n",
        "    'created_datasets_directory'), training_dataset_name)\n",
        "\n",
        "checkpoint_path = os.path.join(get_env_variable(\n",
        "    'trained_models_directory'), f'{model_name}.h5')\n",
        "\n",
        "with open(\"kartAI/config/ml_input_generator/ortofoto.json\", encoding=\"utf8\") as config:\n",
        "    datagenerator_config = json.load(config)\n",
        "\n",
        "predict_and_evaluate(\n",
        "    created_datasets_path=created_datasets_dir,\n",
        "    datagenerator_config=datagenerator_config,\n",
        "    checkpoint_name_to_predict_with=model_name,\n",
        "    save_prediction_images=True,\n",
        "    save_diff_images=True,\n",
        "    generate_metadata=True,\n",
        "    dataset_to_evaluate=\"test\",\n",
        "    batch_size=200\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.2 - Choose a test area\n",
        "Now that we have looked at some stats from the predictions, let's look at some images! First, we need to set a name and the coordinates of the centre for the test region. \n",
        "\n",
        "We have set up three predefined areas to look at:\n",
        "- Kristiansand.\n",
        "- Stavanger.\n",
        "- Bodø.\n",
        "\n",
        "On the other hand, if you want to set up a custom area to look at you have to do the following;\n",
        "\n",
        "1. Go to [geojson.io](https://geojson.io/#map=4.33/65.07/7.88) and draw an area (has to be within Norway). The feature collection for your area will appear on the right side. Copy the code - but make sure the drawn area is not too big!\n",
        "2. Paste the copied feature collection in the \"test_feature\" variable, and uncomment the line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" TODO: Uncomment (remove the #) for the area you want to use, or create a custom area \"\"\"\n",
        "\n",
        "\"\"\" Kristiansand \"\"\"\n",
        "# test_region_name = \"kristiansand\"\n",
        "\n",
        "\"\"\" Stavanger \"\"\"\n",
        "# test_region_name = \"stavanger\"\n",
        "\n",
        "\"\"\" Bodø \"\"\"\n",
        "# test_region_name = \"bodo\"\n",
        "\n",
        "\"\"\"If you want a custom area you can paste a geometry from geojson.io here (see instructions above)\"\"\";\n",
        "test_feature = None #Replace 'None' with a feature collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.3 - Create vector data\n",
        "In the next cell we download a different set of rasters and perform predictions on these. After the predictions are made, we create vector data based on the predictions. The vector data generated can be used to visualize our predictions in a map to see how the model is performing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kartAI.kartai.dataset.create_polygon_dataset import produce_vector_dataset, run_ml_predictions\n",
        "from kartAI.kartai.utils.config_utils import read_config\n",
        "from kartAI.kartai.utils.crs_utils import get_projection_from_config_path\n",
        "from kartAI.kartai.utils.geometry_utils import parse_region_arg, parse_feature_region\n",
        "from kartAI.kartai.utils.prediction_utils import get_raster_predictions_dir, get_vector_predictions_dir\n",
        "import copy\n",
        "\n",
        "if test_feature:\n",
        "    geom = parse_feature_region(copy.deepcopy(test_feature[\"features\"][0]), from_CRS=4326, swap_coords=True)\n",
        "    test_region_name = \"custom_area\"\n",
        "    print(\"geom\", geom)\n",
        "else:\n",
        "  try:\n",
        "    geom = parse_region_arg(f\"kartAI/training_data/regions/{test_region_name}.json\")\n",
        "  except:\n",
        "    print(\"ERROR!\\Missing test_region_name or a test_feature from the previous cell.\")\n",
        "\n",
        "projection = get_projection_from_config_path(\"kartAI/config/dataset/osm_bygg_no_rules.json\")\n",
        "\n",
        "config = read_config(\"kartAI/config/dataset/osm_bygg_no_rules.json\")\n",
        "\n",
        "run_ml_predictions(\n",
        "    input_model_name=model_name, \n",
        "    region_name=test_region_name, \n",
        "    projection=projection,\n",
        "    config=config, \n",
        "    geom=geom, \n",
        "    batch_size=200, \n",
        "    skip_data_fetching=False,\n",
        "    save_to=\"local\", \n",
        "    num_processes=1\n",
        ")\n",
        "\n",
        "vector_output_dir = get_vector_predictions_dir(test_region_name, model_name)\n",
        "raster_predictions_path = get_raster_predictions_dir(test_region_name, model_name)\n",
        "\n",
        "produce_vector_dataset(\n",
        "    output_dir=vector_output_dir, \n",
        "    raster_dir=raster_predictions_path, \n",
        "    config=config, \n",
        "    max_batch_size=200, \n",
        "    modelname=f\"{test_region_name}_{model_name}\", \n",
        "    save_to=\"local\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.4 - Visualize vector data\n",
        "The next cell visualizes the created vector data in a map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "import geopandas as gp\n",
        "import env\n",
        "\n",
        "def add_wms_layer(map):\n",
        "    wms_url = \"https://waapi.webatlas.no/wms-orto/\"\n",
        "    folium.raster_layers.WmsTileLayer(url = f\"{wms_url}?api_key={env.get_env_variable('NK_WMS_API_KEY')}\",\n",
        "                                  layers = 'ortofoto',\n",
        "                                  transparent = True, \n",
        "                                  control = True,\n",
        "                                  fmt=\"image/png\",\n",
        "                                  name = 'ortofoto',\n",
        "                                  overlay = True,\n",
        "                                  show = True,\n",
        "                                  ).add_to(map)\n",
        "\n",
        "\n",
        "\n",
        "polygon_25832 = gp.read_file(f\"results/{test_region_name}/{model_name}/vector/raw_predictions_0.json\")\n",
        "polygon_4326 = polygon_25832.to_crs(4326)\n",
        "\n",
        "center_point = polygon_4326.dissolve().to_crs('+proj=cea').centroid.to_crs(4326)\n",
        "\n",
        "fig = folium.Figure(width=800, height=400)\n",
        "map = folium.Map(location=(center_point.y[0], center_point.x[0]), zoom_start=14)\n",
        "\n",
        "add_wms_layer(map)\n",
        "\n",
        "style = { \"color\": \"#7246C2\", \"weight\": 1, \"fillOpacity\": 0.5 }\n",
        "folium.GeoJson(data=polygon_4326[\"geometry\"], \n",
        "               style_function=lambda x: style\n",
        "               ).add_to(map)\n",
        "fig.add_child(map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.5 - Create contour data\n",
        "Lastly, we create contours. These are similar to the vector data but we can set a cutoff value on how confident the model is that the given area is a building or not. I.e. a contour value of 0.3 means that it will create a polygon around pixels that the model is at least 30% sure is a building, while a contour value of 0.8 creates a polygon around all pixels that the model is 80% sure is a building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kartAI.kartai.dataset.create_polygon_dataset import run_ml_predictions\n",
        "from kartAI.kartai.tools.predict import create_contour_result\n",
        "from kartAI.kartai.utils.config_utils import read_config\n",
        "from kartAI.kartai.utils.crs_utils import get_projection_from_config_path\n",
        "from kartAI.kartai.utils.geometry_utils import parse_region_arg\n",
        "from kartAI.kartai.utils.prediction_utils import get_contour_predictions_dir, get_raster_predictions_dir\n",
        "import copy\n",
        "\n",
        "if test_feature:\n",
        "    geom = parse_feature_region(copy.deepcopy(test_feature[\"features\"][0]), from_CRS=4326, swap_coords=True)\n",
        "    test_region_name = \"custom_area\"\n",
        "    print(\"geom\", geom)\n",
        "else:\n",
        "  try:\n",
        "    geom = parse_region_arg(f\"kartAI/training_data/regions/{test_region_name}.json\")\n",
        "  except:\n",
        "    print(\"ERROR!\\Missing test_region_name or a test_feature from your test area in task 3.2\")\n",
        "\n",
        "\n",
        "projection = get_projection_from_config_path(\"kartAI/config/dataset/osm_bygg_no_rules.json\")\n",
        "\n",
        "config = read_config(\"kartAI/config/dataset/osm_bygg_no_rules.json\")\n",
        "\n",
        "run_ml_predictions(\n",
        "    input_model_name=model_name,\n",
        "    region_name=test_region_name,\n",
        "    projection=projection,\n",
        "    config=config,\n",
        "    geom=geom,\n",
        "    batch_size=200,\n",
        "    skip_data_fetching=False,\n",
        "    save_to=\"local\",\n",
        "    num_processes=1\n",
        ")\n",
        "\n",
        "raster_output_dir = get_raster_predictions_dir(test_region_name, model_name)\n",
        "contour_output_dir = get_contour_predictions_dir(test_region_name, model_name)\n",
        "\n",
        "print(\"---> Creating contour dataset from rasters\")\n",
        "\n",
        "contour_levels = [0.5, 0.8] # Change contour levels here.\n",
        "create_contour_result(raster_output_dir, contour_output_dir, projection, contour_levels)\n",
        "\n",
        "print(\"==== Contour dataset created ====\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3.6 - Visualize contour data\n",
        "The last cell visualizes the contours we generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "import geopandas as gp\n",
        "import math\n",
        "from colour import Color\n",
        "\n",
        "contour_25832 = gp.read_file(f\"results/{test_region_name}/{model_name}/contour/complete_contour.json\")\n",
        "contour_25832[\"geometry\"] = contour_25832.simplify(tolerance=1)\n",
        "contour_4326 = contour_25832.to_crs(4326)\n",
        "\n",
        "center_point = polygon_4326.dissolve().to_crs('+proj=cea').centroid.to_crs(4326)\n",
        "\n",
        "figure = folium.Figure(width=800, height=400)\n",
        "map = folium.Map(location=(center_point.y[0], center_point.x[0]), zoom_start=14)\n",
        "\n",
        "add_wms_layer(map)\n",
        "\n",
        "style = lambda x: { \"color\": list(Color(\"#FFF0F0\").range_to(Color(\"#661100\"), 10))[math.floor(x[\"properties\"][\"elev\"]*10)].hex, \"weight\": 1.5 }\n",
        "\n",
        "folium.GeoJson(\n",
        "    data=contour_4326, \n",
        "    style_function=style\n",
        "    ).add_to(map)\n",
        "figure.add_child(map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Congrats!\n",
        "\n",
        "You have completed the workshop 🚀 \n",
        "\n",
        "If you want, you can go back and choose a different area for training, a different model, change some training parameters etc. – and to see if you can improve the accuracy of your model further! \n",
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
