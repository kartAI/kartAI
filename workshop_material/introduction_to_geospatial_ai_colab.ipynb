{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emBCk06ovP1q"
      },
      "source": [
        "# Introduction to Geospatial AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "Welcome to this workship about geospatial AI! In this workshop you will try to detect buildings from aerial images. This is done in three steps;\n",
        "\n",
        "1. Creating training data.\n",
        "2. Training machine learning models using the created training data.\n",
        "3. Evaluating the trained models and predicting where buildings are located in images the models haven't seen before. \n",
        "\n",
        "We will be using jupyter notebooks with Google Colab, but you don't need to have any experience with these in order to complete this workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 0 - Setup\n",
        "\n",
        "But first, before we can do any of the fun stuff, we need to set up the environment properly. In order to do that follow the steps under;\n",
        "\n",
        "1. Create a Google account, for instance by creating a gmail account. Can be skipped if you already have a gmail account. Log into the account in your browser.\n",
        "2. Head over to https://colab.research.google.com/ and press on the `Github` tab. Search for `kartAI` user and select `kartAI/kartAI` repository. A notebook should appear. Press on this notebook and it should open a notebook in another tab.\n",
        "3. Create a copy of the notebook in your drive by saving it. Shortcut is `Ctrl + s` on Windows or `Cmd + s` on Mac.\n",
        "4. Change to a GPU runtime environment. In the top right corner choose `Change runtime type` and select `T4 GPU`.\n",
        "\n",
        "Nice! Next, we need to clone the git repo we are working with and adding it to the path in addition to installing some dependencies. To do this simply run the two cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fEENVoCvP1q",
        "outputId": "32b51360-456b-468f-de33-dc6c26a0eb55"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kartAI/kartAI.git\n",
        "\n",
        "!pip install focal_loss\n",
        "!pip install azure-storage-blob\n",
        "!pip install rasterio\n",
        "!pip install rasterstats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDdbVLf5vP1r"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/kartAI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 0 - Setup\n",
        "\n",
        "When you have cloned the repo you can insert the secrets. # TODO: Add instructions on how to when open data is ready.\n",
        "\n",
        "The very last thing to do before we can get going on the training data is to set the name of a couple of variables. These are already set to some defaults. You don't need to make any changes unless you really want to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the name of your dataset and model here.\n",
        "# If you want to create a second training dataset or model, you can come back and change the name here. \n",
        "# Remember to change the area and centre_of_area if you want to train on a different area.\n",
        "training_dataset_name = \"best_training_dataset\"\n",
        "model_name = \"super_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1 - Training Data\n",
        "In the first task we create the training data. This is done by selecting an area you want to train on, then download aerial photos in addition to data about all the existing buildings in the chosen area. \n",
        "\n",
        "In the next cell, choose which area you want to train from. There is 3 areas you can choose from. You can also define your own area. Head over to https://geojson.io/ to find coordinates and train your model on your custom area. NB!! We dont have a dataset over all of norway, so you might have missing data if you chose an area that's not covered. Also, you need to convert the coordinates to a different coordinate system..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are three predefined areas you can choose from. To choose another area comment in the other area and corresponding centre of that area.\n",
        "\n",
        "# This area is Jessheim\n",
        "area = { \"x_min\": 618296.0, \"x_max\": 621495.0, \"y_min\": 6668145.0, \"y_max\": 6670133.0 }\n",
        "centre_of_area = [619000.0, 6669500]\n",
        "\n",
        "# This area is Sk√∏yen, Oslo\n",
        "# area = { \"x_min\": 567450.9, \"x_max\": 583932.4, \"y_min\": 6644019.8, \"y_max\": 6644490.2 }\n",
        "# centre_of_area = [567450.9, 6644490.2]\n",
        "\n",
        "# This area is Midtbyen, Trondheim\n",
        "# area = { \"x_min\": 569372.6, \"x_max\": 569820.4, \"y_min\": 7033816.7, \"y_max\": 7034223.7 }\n",
        "# centre_of_area = [569372.6, 7034223.7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1 - Training Data\n",
        "When you have chosen the area you can run the cell after in order to create the training data. The training data is downloaded as rasters (images) and split into a training, validation and test set. The model will train on the training set, and while training run tests on the validation set. After the training is finished it will run tests on the tests set - data the model have never seen before.\n",
        "\n",
        "While downloading the rasters, it will say how many rasters total it will download. The training data download is quite time consuming, so if you make a custom area, make sure it downloads maximum about ~700 rasters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vAvL9gJ2vP1r",
        "outputId": "8be86582-9805-4289-d091-1c33c684e8b7"
      },
      "outputs": [],
      "source": [
        "from kartAI.kartai.tools.create_training_data import create_training_data\n",
        "\n",
        "create_training_data(\n",
        "    training_dataset_name=training_dataset_name, \n",
        "    config_file_path=\"kartAI/config/dataset/bygg.json\", \n",
        "    eager_load=True,\n",
        "    confidence_threshold=None, \n",
        "    eval_model_checkpoint=None,\n",
        "    region=None, \n",
        "    x_min=area[\"x_min\"], \n",
        "    x_max=area[\"x_max\"], \n",
        "    y_min=area[\"y_min\"], \n",
        "    y_max=area[\"y_max\"],\n",
        "    num_processes=None                 \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1 - Training Data\n",
        "After downloading the data you can visualize it in the next cell. Make sure the path to the training data is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "from pyproj import CRS, Transformer\n",
        "\n",
        "path_to_dir = \"/content/training_data/OrtofotoWMS/25832_563000.0_6623000.0_100.0_100.0/512/\" # Make sure to have the correct path to the training data.\n",
        "files = os.listdir(path_to_dir)\n",
        "files.sort()\n",
        "\n",
        "crs_25832 = CRS.from_epsg(25832)\n",
        "crs_4326 = CRS.from_epsg(4326)\n",
        "transformer = Transformer.from_crs(crs_25832, crs_4326)\n",
        "\n",
        "fig = folium.Figure(width=800, height=400)\n",
        "m = folium.Map(\n",
        "    location=transformer.transform(centre_of_area[0], centre_of_area[1]), \n",
        "    zoom_start=14\n",
        ")\n",
        "\n",
        "for i in range(5): # Load 5 rasters. Change this to load fewer/more rasters. Be aware that loading many rasters is slow.\n",
        "    with rasterio.open(f\"{path_to_dir}{files[i]}\") as src:\n",
        "        img = src.read()\n",
        "        transformed_bottom_left = transformer.transform(src.bounds.left, src.bounds.bottom)\n",
        "        transformed_top_right = transformer.transform(src.bounds.right, src.bounds.top)\n",
        "    m.add_child(folium.raster_layers.ImageOverlay(img.transpose(1, 2, 0), bounds = [transformed_bottom_left, transformed_top_right]))\n",
        "\n",
        "fig.add_child(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2 - Machine Learning Model\n",
        "After creating and visualizing the training data we are ready to train our model! The training performs what is known as per-pixel classification. In other words, the model tries to assign a class (either a building or not a building) for each pixel in the raster based on the input features. After the model is trained we can create vector data from the predicted pixels and therefore end up with bounding boxes we can look at!\n",
        "\n",
        "In the next cell you can tune some hyperparameters, but make sure the training doesn't take too long. The default configuration should take about ~15 minutes to execute and should get you a _decent_ model.\n",
        "\n",
        "While training some statistics about the training is showing. They can be a little bit confusing, and it's not a must to understand all of them. The stats showing are;\n",
        "\n",
        " - Loss: A measurement of how wrong the model is. The lower the loss is, the better. If the loss is 0, the model is \"perfect\". A model tries to minimize this value.\n",
        " - Binary Accuracy: A measurement of how many of the predicted pixels are inside a building. It's a number between 0 and 1, where higher is better. 1 means all the pixels the model says are within a building is actually within a building. But keep in mind even if the number is 1, the model might not have made predictions for all pixels in all buildings...\n",
        " - IoU: Intersection over Union. A measurement of how much of the estimated area overlaps with a building. It's a number between 0 and 1, where higher is better. 1 means the model is fitting the bounding box of all buildings \"perfectly\".\n",
        " - IoU_fz: Fuzzy set variant of IoU. Shares similar characteristics as described earlier.\n",
        " - IoU_point_[5-9]: Cutoff values for IoU. It's a measurement of what the IoU would be if the cutoff values was [5-9].\n",
        " - val_x: The validation equivalent of whatever x is. X could be loss, IoU, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s07L5WvTJhLz",
        "outputId": "1b2ba046-e93b-4ec3-ca36-36bd2bc5eba6"
      },
      "outputs": [],
      "source": [
        "from kartAI.kartai.tools.train import train\n",
        "\n",
        "train_args = {\n",
        "      \"features\": 32,\n",
        "      \"depth\": 4,\n",
        "      \"optimizer\": \"RMSprop\",\n",
        "      \"batch_size\": 8,\n",
        "      \"model\": \"unet\",\n",
        "      \"loss\": \"binary_crossentropy\",\n",
        "      \"activation\": \"relu\",\n",
        "      \"epochs\": 20\n",
        "}\n",
        "\n",
        "\n",
        "train(\n",
        "      checkpoint_name=model_name,\n",
        "      dataset_name=[training_dataset_name],\n",
        "      input_generator_config_path=\"kartAI/config/ml_input_generator/ortofoto.json\",\n",
        "      save_model=False,\n",
        "      train_args=train_args,\n",
        "      checkpoint_to_finetune=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3 - Evaluation and Inference\n",
        "For the last part we will use our trained machine learning model and try to find buildings in a new set of images we haven't seen so far. The next cell runs predictions on the test portion of the downloaded training data. The same statistics as the ones described during training shows up, in addition to;\n",
        "\n",
        " - Confidence: Tells us how confident the model is. It is a number between 0 and 1, where higher is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_aMcP6Njm3d",
        "outputId": "0874bd77-9ad4-4be9-b4ab-a5925bfd5593"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from kartAI.env import get_env_variable\n",
        "from kartAI.kartai.tools.predict import predict_and_evaluate\n",
        "\n",
        "created_datasets_dir = os.path.join(get_env_variable(\n",
        "    'created_datasets_directory'), training_dataset_name)\n",
        "\n",
        "checkpoint_path = os.path.join(get_env_variable(\n",
        "    'trained_models_directory'), f'{model_name}.h5')\n",
        "\n",
        "with open(\"kartAI/config/ml_input_generator/ortofoto.json\", encoding=\"utf8\") as config:\n",
        "    datagenerator_config = json.load(config)\n",
        "\n",
        "predict_and_evaluate(\n",
        "    created_datasets_path=created_datasets_dir,\n",
        "    datagenerator_config=datagenerator_config,\n",
        "    checkpoint_name_to_predict_with=model_name,\n",
        "    save_prediction_images=True,\n",
        "    save_diff_images=True,\n",
        "    generate_metadata=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3 - Evaluation and Inference\n",
        "Now that we have looked at some stats from the predictions, let's look at some images! In the next cell we download a different set of rasters and perform predictions on these. After the predictions are made, we create vector data based on the predictions. The vector data generated can be used to visualize our predictions in a map to see how the model is performing.\n",
        "\n",
        "But first, we need to set a name for the test region.\n",
        "# TODO: Add supported test regions when open data is ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Name of test region. See supported names above.\n",
        "test_region_name = \"small_test_region\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kartAI.kartai.dataset.create_building_dataset import produce_vector_buildings, run_ml_predictions\n",
        "from kartAI.kartai.utils.config_utils import read_config\n",
        "from kartAI.kartai.utils.crs_utils import get_projection_from_config_path\n",
        "from kartAI.kartai.utils.geometry_utils import parse_region_arg\n",
        "from kartAI.kartai.utils.prediction_utils import get_raster_predictions_dir, get_vector_predictions_dir\n",
        "\n",
        "geom = parse_region_arg(\"kartAI/training_data/regions/{test_region_name}.json\")\n",
        "\n",
        "projection = get_projection_from_config_path(\"kartAI/config/dataset/bygg.json\")\n",
        "\n",
        "config = read_config(\"kartAI/config/dataset/bygg.json\")\n",
        "\n",
        "run_ml_predictions(\n",
        "    input_model_name=model_name, \n",
        "    region_name=test_region_name, \n",
        "    projection=projection,\n",
        "    config=config, \n",
        "    geom=geom, \n",
        "    batch_size=200, \n",
        "    skip_data_fetching=False,\n",
        "    save_to=\"local\", \n",
        "    num_processes=1\n",
        ")\n",
        "\n",
        "vector_output_dir = get_vector_predictions_dir(test_region_name, model_name)\n",
        "raster_predictions_path = get_raster_predictions_dir(test_region_name, model_name)\n",
        "\n",
        "produce_vector_buildings(\n",
        "    output_dir=vector_output_dir, \n",
        "    raster_dir=raster_predictions_path, \n",
        "    config=config, \n",
        "    max_batch_size=200, \n",
        "    modelname=f\"{test_region_name}_{model_name}\", \n",
        "    save_to=\"local\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3 - Evaluation and Inference\n",
        "The next cell visualizes the created vector data in a map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import folium\n",
        "import geopandas as gp\n",
        "\n",
        "polygon_25832 = gp.read_file(f\"results/{test_region_name}/{model_name}/vector/raw_predictions_0.json\")\n",
        "polygon_4326 = polygon_25832.to_crs(4326)\n",
        "\n",
        "fig = folium.Figure(width=800, height=400)\n",
        "map = folium.Map(location=transformer.transform(centre_of_area[0], centre_of_area[1]), zoom_start=14)\n",
        "folium.GeoJson(data=polygon_4326[\"geometry\"]).add_to(map)\n",
        "fig.add_child(map)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
